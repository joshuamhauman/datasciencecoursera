library(evaluate)
library(formatR)
library(highr)
library(markdown)
library(knitr)
library(rmarkdown)
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
set.seed(12345)

## Load and view the data ##

trainingUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

trainingData <- read.csv(url(trainingUrl), na.strings=c("NA","#DIV/0!",""))
testData <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))

str(trainingData)


## Split the Traning data ##

inTraining <- createDataPartition(trainingData$classe, p = 0.7, list = FALSE)
training <- trainingData[inTraining, ]
testing <- trainingData[-inTraining, ]
dim(training); dim(testing)


## Clean the data ##

##  Remove variables with NearZero Variance  ##

NZV <- nearZeroVar(training)
training <-training[, -NZV]
testing  <- testing[, -NZV]
dim(training); dim(testing)

## Remove variables that are mostly NA ##

NAs    <- sapply(training, function(x) mean(is.na(x))) > 0.95
training <- training[, NAs==FALSE]
testing  <- testing[, NAs==FALSE]
dim(training); dim(testing)

## Decision tree Predicion ##
trainingControl <- trainControl(method="cv", number=3)
model_CT <- train(classe~., data=training, method="rpart", trainingControl=trainingControl)

CT <- rpart(classe ~ ., data=training, method="class")
fancyRpartPlot(CT)

## Create confusion matrix ##

CTpredict <- predict(CT, testing, type = "class")
cmtree <- confusionMatrix(CTpredict, testing$classe)
cmtree

## Plot Confusion matrix ##

plot(cmtree$table, col = cmtree$byClass, main = paste("Decision Tree Confusion Matrix: Accuracy =", round(cmtree$overall['Accuracy'], 4)))

##Random Forest prediction ##

set.seed(12345)
RF <- randomForest(classe ~ ., data=training)
RFpredict <- predict(RF, testing, type = "class")
cmrf <- confusionMatrix(RFpredict, testing$classe)
cmrf

## Confusion Matrix and Statistics
##  
##            Reference
##  Prediction    A    B    C    D    E
##           A 1674    0    0    0    0
##           B    0 1139    0    0    0
##           C    0    0 1026    0    0
##           D    0    0    0  964    0
##           E    0    0    0    0 1082
##  
##  Overall Statistics
##                                       
##                 Accuracy : 1          
##                   95% CI : (0.9994, 1)
##      No Information Rate : 0.2845     
##      P-Value [Acc > NIR] : < 2.2e-16  
##                                       
##                    Kappa : 1          
##   Mcnemar's Test P-Value : NA         
##  
##  Statistics by Class:
##  
##                       Class: A Class: B Class: C Class: D Class: E
##  Sensitivity            1.0000   1.0000   1.0000   1.0000   1.0000
##  Specificity            1.0000   1.0000   1.0000   1.0000   1.0000
##  Pos Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
##  Neg Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
##  Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
##  Detection Rate         0.2845   0.1935   0.1743   0.1638   0.1839
##  Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
##  Balanced Accuracy      1.0000   1.0000   1.0000   1.0000   1.0000

## Plot Random Forest ##

plot(RF)

## Plot confusion matrix ##
plot(cmrf$table, col = cmtree$byClass, main = paste("Random Forest Confusion Matrix: Accuracy =", round(cmrf$overall['Accuracy'], 4)))

## Predict results on testing data ##

predictTEST <- predict(RF, data=testing)
predictTEST




##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E



##  Confusion Matrix and Statistics
##
##          Reference
##  Prediction    A    B    C    D    E
##           A 1672    0    0    0    0
##           B    2 1138    0    0    0
##           C    0    1 1026    0    0
##           D    0    0    0  964    0
##           E    0    0    0    0 1082
##
##  Overall Statistics
##                                          
##               Accuracy : 0.9995          
##                 95% CI : (0.9985, 0.9999)
##    No Information Rate : 0.2845          
##    P-Value [Acc > NIR] : < 2.2e-16       
##                                          
##                   Kappa : 0.9994          
##  Mcnemar's Test P-Value : NA              
##
##  Statistics by Class:
##
##                        Class: A Class: B Class: C Class: D Class: E
##  Sensitivity            0.9988   0.9991   1.0000   1.0000   1.0000
##  Specificity            1.0000   0.9996   0.9998   1.0000   1.0000
##  Pos Pred Value         1.0000   0.9982   0.9990   1.0000   1.0000
##  Neg Pred Value         0.9995   0.9998   1.0000   1.0000   1.0000
##  Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
##  Detection Rate         0.2841   0.1934   0.1743   0.1638   0.1839
##  Detection Prevalence   0.2841   0.1937   0.1745   0.1638   0.1839
##  Balanced Accuracy      0.9994   0.9994   0.9999   1.0000   1.0000


